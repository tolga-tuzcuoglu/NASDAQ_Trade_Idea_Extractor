{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üöÄ Nasdaq Trader - Production Pipeline\n",
    "\n",
    "**Professional Trading Analysis from YouTube Videos**\n",
    "\n",
    "## üéØ Overview\n",
    "This production-ready notebook provides a clean, professional interface for analyzing Turkish trading videos and generating actionable Nasdaq trading reports.\n",
    "\n",
    "## üìã Prerequisites\n",
    "- Python 3.8+ environment\n",
    "- Required dependencies installed (`pip install -r requirements.txt`)\n",
    "- `GEMINI_API_KEY` environment variable set\n",
    "- Video URLs in `video_list.txt`\n",
    "\n",
    "## üöÄ Quick Start\n",
    "1. **Setup**: Run the setup cell below\n",
    "2. **Configure**: Add video URLs to `video_list.txt`\n",
    "3. **Execute**: Run the processing pipeline\n",
    "4. **Review**: Check generated reports in `summary/` folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Production Environment Setup\n",
      "==================================================\n",
      "Python version: 3.12.7 | packaged by Anaconda, Inc. | (main, Oct  4 2024, 13:17:27) [MSC v.1929 64 bit (AMD64)]\n",
      "‚ùå GEMINI_API_KEY not found - please set this environment variable\n",
      "‚úÖ Found 1 videos in video_list.txt\n",
      "\n",
      "üöÄ Environment ready for production processing!\n"
     ]
    }
   ],
   "source": [
    "# Production Setup and Configuration\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Add current directory to path\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "# Check environment\n",
    "print(\"üîß Production Environment Setup\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Check Python version\n",
    "print(f\"Python version: {sys.version}\")\n",
    "\n",
    "# Check required environment variables\n",
    "gemini_key = os.getenv('GEMINI_API_KEY')\n",
    "if gemini_key:\n",
    "    print(\"‚úÖ GEMINI_API_KEY found\")\n",
    "else:\n",
    "    print(\"‚ùå GEMINI_API_KEY not found - please set this environment variable\")\n",
    "\n",
    "# Check video list\n",
    "if os.path.exists('video_list.txt'):\n",
    "    with open('video_list.txt', 'r', encoding='utf-8') as f:\n",
    "        video_urls = [line.strip() for line in f if line.strip() and not line.startswith('#')]\n",
    "    print(f\"‚úÖ Found {len(video_urls)} videos in video_list.txt\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  video_list.txt not found - please create it with video URLs\")\n",
    "\n",
    "print(\"\\nüöÄ Environment ready for production processing!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üé¨ Video Processing Pipeline\n",
    "\n",
    "**Execute the complete trading analysis pipeline**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-12 07:12:19,517 | INFO | System optimized for high performance\n",
      "2025-10-12 07:12:19,519 | INFO | Processing: https://www.youtube.com/watch?v=K8TFnwpDoAE\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting Production Video Processing\n",
      "==================================================\n",
      "Found 1 videos to process:\n",
      "   1. https://www.youtube.com/watch?v=K8TFnwpDoAE\n",
      "\n",
      "Starting processing for 1 videos...\n",
      "\n",
      "--- Video 1/1 ---\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-12 07:12:30,871 | INFO | Transcribing audio: video_cache/K8TFnwpDoAE_20251012.m4a\n"
     ]
    }
   ],
   "source": [
    "# Self-Contained Trading Analysis Engine\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import multiprocessing\n",
    "import concurrent.futures\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import psutil\n",
    "import yaml\n",
    "from datetime import datetime\n",
    "import whisper\n",
    "import google.generativeai as genai\n",
    "from yt_dlp import YoutubeDL\n",
    "import yfinance as yf\n",
    "from dotenv import load_dotenv\n",
    "import warnings\n",
    "import json\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "class SelfContainedNasdaqTrader:\n",
    "    def __init__(self):\n",
    "        self.config = self.load_config()\n",
    "        self.setup_logging()\n",
    "        self.system_info = self.get_system_info()\n",
    "        self.optimal_settings = self.calculate_optimal_settings()\n",
    "        \n",
    "        print(f\"üöÄ Self-Contained Nasdaq Trader Initialized\")\n",
    "        print(f\"   System: {self.system_info['cpu_cores']} cores, {self.system_info['ram_gb']:.1f}GB RAM\")\n",
    "        print(f\"   Optimal: {self.optimal_settings['parallel_videos']} parallel videos\")\n",
    "    \n",
    "    def load_config(self):\n",
    "        \"\"\"Load configuration with defaults\"\"\"\n",
    "        try:\n",
    "            with open('config.yaml', 'r', encoding='utf-8') as f:\n",
    "                return yaml.safe_load(f)\n",
    "        except:\n",
    "            return {\n",
    "                \"ACCELERATION\": {\n",
    "                    \"parallel_videos\": 2,\n",
    "                    \"max_workers\": 4,\n",
    "                    \"use_gpu\": False,\n",
    "                    \"optimize_memory\": True\n",
    "                },\n",
    "                \"MODELS\": {\n",
    "                    \"whisper_model\": \"small\",\n",
    "                    \"gemini_model\": \"gemini-2.5-flash\"\n",
    "                }\n",
    "            }\n",
    "    \n",
    "    def get_system_info(self):\n",
    "        \"\"\"Get system information for optimization\"\"\"\n",
    "        return {\n",
    "            \"cpu_cores\": multiprocessing.cpu_count(),\n",
    "            \"ram_gb\": psutil.virtual_memory().total / (1024**3),\n",
    "            \"available_ram_gb\": psutil.virtual_memory().available / (1024**3),\n",
    "            \"cpu_usage\": psutil.cpu_percent(interval=1)\n",
    "        }\n",
    "    \n",
    "    def calculate_optimal_settings(self):\n",
    "        \"\"\"Calculate optimal processing settings based on system specs\"\"\"\n",
    "        cpu_cores = self.system_info['cpu_cores']\n",
    "        available_ram = self.system_info['available_ram_gb']\n",
    "        \n",
    "        if cpu_cores >= 8:\n",
    "            parallel_videos = min(4, cpu_cores // 2)\n",
    "            max_workers = cpu_cores\n",
    "        elif cpu_cores >= 4:\n",
    "            parallel_videos = min(3, cpu_cores // 2)\n",
    "            max_workers = cpu_cores\n",
    "        else:\n",
    "            parallel_videos = 1\n",
    "            max_workers = max(2, cpu_cores)\n",
    "        \n",
    "        if available_ram >= 16:\n",
    "            batch_size = 4\n",
    "            quality_mode = \"balanced\"\n",
    "        elif available_ram >= 8:\n",
    "            batch_size = 3\n",
    "            quality_mode = \"fast\"\n",
    "        else:\n",
    "            batch_size = 2\n",
    "            quality_mode = \"fast\"\n",
    "        \n",
    "        return {\n",
    "            \"parallel_videos\": parallel_videos,\n",
    "            \"max_workers\": max_workers,\n",
    "            \"batch_size\": batch_size,\n",
    "            \"quality_mode\": quality_mode,\n",
    "            \"use_gpu\": self.check_gpu_availability()\n",
    "        }\n",
    "    \n",
    "    def check_gpu_availability(self):\n",
    "        \"\"\"Check if GPU is available for processing\"\"\"\n",
    "        try:\n",
    "            import torch\n",
    "            return torch.cuda.is_available()\n",
    "        except ImportError:\n",
    "            return False\n",
    "    \n",
    "    def setup_logging(self):\n",
    "        \"\"\"Setup logging configuration\"\"\"\n",
    "        logging.basicConfig(\n",
    "            level=logging.INFO,\n",
    "            format=\"%(asctime)s | %(levelname)s | %(message)s\",\n",
    "            handlers=[\n",
    "                logging.StreamHandler(),\n",
    "                logging.FileHandler(\"logs/self_contained_trader.log\")\n",
    "            ]\n",
    "        )\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "    \n",
    "    def optimize_system(self):\n",
    "        \"\"\"Optimize system for better performance\"\"\"\n",
    "        try:\n",
    "            p = psutil.Process()\n",
    "            p.nice(psutil.HIGH_PRIORITY_CLASS)\n",
    "            self.logger.info(\"System optimized for high performance\")\n",
    "        except Exception as e:\n",
    "            self.logger.warning(f\"Could not optimize system: {e}\")\n",
    "    \n",
    "    def load_video_urls(self):\n",
    "        \"\"\"Load video URLs from various sources\"\"\"\n",
    "        urls = []\n",
    "        \n",
    "        # Try environment variables first\n",
    "        env_url = os.getenv('VIDEO_URL')\n",
    "        env_urls = os.getenv('VIDEO_URLS')\n",
    "        \n",
    "        if env_url:\n",
    "            urls.append(env_url)\n",
    "        elif env_urls:\n",
    "            urls.extend([url.strip() for url in env_urls.split(',') if url.strip()])\n",
    "        \n",
    "        # Fall back to video_list.txt\n",
    "        if not urls and os.path.exists('video_list.txt'):\n",
    "            try:\n",
    "                with open('video_list.txt', 'r', encoding='utf-8') as f:\n",
    "                    urls = [line.strip() for line in f if line.strip() and not line.startswith('#')]\n",
    "            except Exception as e:\n",
    "                self.logger.error(f\"Error reading video_list.txt: {e}\")\n",
    "        \n",
    "        return urls\n",
    "    \n",
    "    def download_video(self, url):\n",
    "        \"\"\"Download video and extract audio\"\"\"\n",
    "        try:\n",
    "            os.makedirs('video_cache', exist_ok=True)\n",
    "            date_str = datetime.now().strftime('%Y%m%d')\n",
    "            \n",
    "            ydl_opts = {\n",
    "                'format': 'bestaudio[ext=m4a]/bestaudio/best',\n",
    "                'outtmpl': f'video_cache/%(id)s_{date_str}.%(ext)s',\n",
    "                'extractaudio': True,\n",
    "                'audioformat': 'wav',\n",
    "                'noplaylist': True,\n",
    "                'quiet': True,\n",
    "                'no_warnings': True\n",
    "            }\n",
    "            \n",
    "            with YoutubeDL(ydl_opts) as ydl:\n",
    "                info = ydl.extract_info(url, download=True)\n",
    "                video_id = info.get('id', 'unknown')\n",
    "                \n",
    "                for ext in ['m4a', 'wav', 'mp3', 'webm']:\n",
    "                    audio_path = f'video_cache/{video_id}_{date_str}.{ext}'\n",
    "                    if os.path.exists(audio_path):\n",
    "                        return audio_path\n",
    "                \n",
    "                raise Exception(\"Audio file not found after download\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Download failed for {url}: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def transcribe_audio(self, audio_path):\n",
    "        \"\"\"Transcribe audio using Whisper with caching\"\"\"\n",
    "        try:\n",
    "            os.makedirs('transcript_cache', exist_ok=True)\n",
    "            \n",
    "            date_str = datetime.now().strftime('%Y%m%d')\n",
    "            video_id = os.path.basename(audio_path).split('.')[0].split('_')[0]\n",
    "            transcript_cache_path = f'transcript_cache/{video_id}_{date_str}.txt'\n",
    "            \n",
    "            if os.path.exists(transcript_cache_path):\n",
    "                self.logger.info(f\"Using cached transcript for {video_id}\")\n",
    "                with open(transcript_cache_path, 'r', encoding='utf-8') as f:\n",
    "                    return f.read()\n",
    "            \n",
    "            self.logger.info(f\"Transcribing audio: {audio_path}\")\n",
    "            model = whisper.load_model(self.config.get('MODELS', {}).get('whisper_model', 'small'))\n",
    "            result = model.transcribe(audio_path, language='tr')\n",
    "            transcript_text = result['text']\n",
    "            \n",
    "            with open(transcript_cache_path, 'w', encoding='utf-8') as f:\n",
    "                f.write(transcript_text)\n",
    "            self.logger.info(f\"Transcript cached: {transcript_cache_path}\")\n",
    "            \n",
    "            return transcript_text\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Transcription failed: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def generate_analysis(self, transcript):\n",
    "        \"\"\"Generate AI analysis using Gemini\"\"\"\n",
    "        try:\n",
    "            api_key = os.getenv('GEMINI_API_KEY')\n",
    "            if not api_key:\n",
    "                raise Exception(\"GEMINI_API_KEY not found in environment\")\n",
    "            \n",
    "            genai.configure(api_key=api_key)\n",
    "            model = genai.GenerativeModel(self.config.get('MODELS', {}).get('gemini_model', 'gemini-2.5-flash'))\n",
    "            \n",
    "            prompt = f\"\"\"\n",
    "            As an experienced Nasdaq portfolio manager, analyze this Turkish trading video transcript and create a professional trading report.\n",
    "            \n",
    "            TRANSCRIPT:\n",
    "            {transcript}\n",
    "            \n",
    "            Create a comprehensive trading analysis report in this EXACT format:\n",
    "            \n",
    "            # NASDAQ TRADING ANALYSIS REPORT\n",
    "            \n",
    "            ## üìä VIDEO INFORMATION\n",
    "            - **Date**: [Extract video date if mentioned, otherwise use current date]\n",
    "            - **Video URL**: [Video URL if available]\n",
    "            - **Video Title**: [Video title if mentioned]\n",
    "            - **Channel/Author**: [Channel name or author if mentioned]\n",
    "            \n",
    "            ## üéØ EXECUTIVE SUMMARY\n",
    "            [2-3 sentence summary of key trading opportunities and market outlook]\n",
    "            \n",
    "            ## üìà ACTIONABLE TRADE IDEAS\n",
    "            ### Day Trading Opportunities\n",
    "            - **Ticker**: [SYMBOL] | **Action**: [BUY/SELL] | **Entry**: [Price] | **Target**: [Price] | **Stop**: [Price] | **Timeframe**: [Hours/Days]\n",
    "            \n",
    "            ### Swing Trading Opportunities  \n",
    "            - **Ticker**: [SYMBOL] | **Action**: [BUY/SELL] | **Entry**: [Price] | **Target**: [Price] | **Stop**: [Price] | **Timeframe**: [Days/Weeks]\n",
    "            \n",
    "            ### Long-term Investment Ideas\n",
    "            - **Ticker**: [SYMBOL] | **Action**: [BUY/HOLD] | **Entry**: [Price Range] | **Target**: [Price] | **Timeframe**: [Months/Years]\n",
    "            \n",
    "            ## üè¢ VALIDATED TICKERS & ASSETS\n",
    "            ### Stocks (NASDAQ/NYSE)\n",
    "            - [TICKER] - [Company Name] - [Current Price if mentioned]\n",
    "            \n",
    "            ### Cryptocurrencies\n",
    "            - [SYMBOL] (Bitcoin, Ethereum, etc.) - [Current Price if mentioned]\n",
    "            \n",
    "            ### Commodities\n",
    "            - [ASSET] (Gold, Silver, Oil, etc.) - [Current Price if mentioned]\n",
    "            \n",
    "            ## üìä TECHNICAL ANALYSIS\n",
    "            ### Support & Resistance Levels\n",
    "            - **Ticker**: [SYMBOL] | **Support**: [Price] | **Resistance**: [Price]\n",
    "            \n",
    "            ### Chart Patterns\n",
    "            - **Ticker**: [SYMBOL] | **Pattern**: [Pattern Name] | **Implication**: [Bullish/Bearish/Neutral]\n",
    "            \n",
    "            ### Key Levels\n",
    "            - **Ticker**: [SYMBOL] | **Key Level**: [Price] | **Significance**: [Breakout/Support/Resistance]\n",
    "            \n",
    "            ## üì∞ MARKET SENTIMENT & NEWS\n",
    "            ### Positive Catalysts\n",
    "            - [Specific positive news or events mentioned]\n",
    "            \n",
    "            ### Risk Factors\n",
    "            - [Specific risks or negative factors mentioned]\n",
    "            \n",
    "            ### Market Outlook\n",
    "            - [Overall market direction and reasoning]\n",
    "            \n",
    "            ## ‚è∞ TIMING & DURATION\n",
    "            ### Immediate Actions (0-24 hours)\n",
    "            - [Specific actions to take immediately]\n",
    "            \n",
    "            ### Short-term (1-7 days)\n",
    "            - [Actions for the coming week]\n",
    "            \n",
    "            ### Medium-term (1-4 weeks)\n",
    "            - [Actions for the coming month]\n",
    "            \n",
    "            ## üéØ PORTFOLIO IMPLICATIONS\n",
    "            ### Position Sizing\n",
    "            - [Recommended position sizes for different risk levels]\n",
    "            \n",
    "            ### Risk Management\n",
    "            - [Specific risk management strategies mentioned]\n",
    "            \n",
    "            ### Diversification\n",
    "            - [Diversification recommendations]\n",
    "            \n",
    "            ## üìã TRADING CHECKLIST\n",
    "            - [ ] [Specific action item 1]\n",
    "            - [ ] [Specific action item 2]\n",
    "            - [ ] [Specific action item 3]\n",
    "            \n",
    "            ## ‚ö†Ô∏è IMPORTANT DISCLAIMERS\n",
    "            - This analysis is based solely on the video content\n",
    "            - All tickers and prices should be verified before trading\n",
    "            - Past performance does not guarantee future results\n",
    "            - Always use proper risk management\n",
    "            \n",
    "            **CRITICAL ANTI-HALLUCINATION REQUIREMENTS:**\n",
    "            \n",
    "            üö´ **STRICT PROHIBITIONS:**\n",
    "            - NEVER add tickers, prices, or information not explicitly mentioned in the transcript\n",
    "            - NEVER use external knowledge or current market data\n",
    "            - NEVER assume or infer information not directly stated\n",
    "            - NEVER add technical analysis not explicitly described in the video\n",
    "            - NEVER include market news or events not mentioned in the transcript\n",
    "            \n",
    "            ‚úÖ **MANDATORY REQUIREMENTS:**\n",
    "            1. ONLY include tickers and assets explicitly mentioned in the transcript\n",
    "            2. ONLY include prices that are explicitly stated in the video\n",
    "            3. ONLY include technical analysis that is explicitly described\n",
    "            4. ONLY include trading ideas that are explicitly mentioned\n",
    "            5. If information is not in the transcript, state \"Not mentioned in video\"\n",
    "            6. Use exact quotes from the transcript when possible\n",
    "            7. Clearly mark any assumptions or interpretations as \"Based on transcript interpretation\"\n",
    "            8. Validate all ticker symbols (use standard format like AAPL, MSFT, etc.)\n",
    "            9. If prices are mentioned, include them; if not, state \"Price not specified in video\"\n",
    "            10. Be specific about entry/exit points only if explicitly mentioned\n",
    "            11. Focus on actionable information that can be executed on NASDAQ\n",
    "            12. Maintain professional trading report format\n",
    "            \n",
    "            üîç **SOURCE VERIFICATION:**\n",
    "            - Every piece of information must be traceable to the transcript\n",
    "            - Use phrases like \"According to the video\" or \"The speaker mentioned\"\n",
    "            - If uncertain, state \"Unclear from transcript\" rather than guessing\n",
    "            - Never fill in gaps with external knowledge\n",
    "            \n",
    "            üìù **REPORTING STANDARDS:**\n",
    "            - If no trading ideas are mentioned, state \"No specific trading ideas mentioned in video\"\n",
    "            - If no tickers are mentioned, state \"No ticker symbols mentioned in video\"\n",
    "            - If no prices are mentioned, state \"No price targets mentioned in video\"\n",
    "            - Always prioritize accuracy over completeness\n",
    "            \"\"\"\n",
    "            \n",
    "            response = model.generate_content(prompt)\n",
    "            return response.text\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"AI analysis failed: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def save_report(self, analysis, url):\n",
    "        \"\"\"Save analysis report to file\"\"\"\n",
    "        try:\n",
    "            os.makedirs('summary', exist_ok=True)\n",
    "            \n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            video_id = url.split('v=')[-1].split('&')[0] if 'v=' in url else 'unknown'\n",
    "            \n",
    "            txt_filename = f'summary/report_{video_id}_{timestamp}.txt'\n",
    "            with open(txt_filename, 'w', encoding='utf-8') as f:\n",
    "                f.write(f\"Trading Analysis Report\\n\")\n",
    "                f.write(f\"Video URL: {url}\\n\")\n",
    "                f.write(f\"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "                f.write(f\"{'='*50}\\n\\n\")\n",
    "                f.write(analysis)\n",
    "            \n",
    "            json_filename = f'summary/report_{video_id}_{timestamp}.json'\n",
    "            report_data = {\n",
    "                'url': url,\n",
    "                'timestamp': timestamp,\n",
    "                'analysis': analysis,\n",
    "                'generated_at': datetime.now().isoformat()\n",
    "            }\n",
    "            \n",
    "            with open(json_filename, 'w', encoding='utf-8') as f:\n",
    "                json.dump(report_data, f, indent=2, ensure_ascii=False)\n",
    "            \n",
    "            print(f\"Report saved: {txt_filename}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Failed to save report: {e}\")\n",
    "    \n",
    "    def process_single_video(self, url):\n",
    "        \"\"\"Process a single video with all steps\"\"\"\n",
    "        start_time = time.time()\n",
    "        \n",
    "        try:\n",
    "            self.logger.info(f\"Processing: {url}\")\n",
    "            \n",
    "            # Download video\n",
    "            audio_path = self.download_video(url)\n",
    "            if not audio_path:\n",
    "                raise Exception(\"Failed to download video\")\n",
    "            \n",
    "            # Transcribe audio\n",
    "            transcript = self.transcribe_audio(audio_path)\n",
    "            if not transcript:\n",
    "                raise Exception(\"Failed to transcribe audio\")\n",
    "            \n",
    "            # Generate AI analysis\n",
    "            analysis = self.generate_analysis(transcript)\n",
    "            if not analysis:\n",
    "                raise Exception(\"Failed to generate analysis\")\n",
    "            \n",
    "            # Save report\n",
    "            self.save_report(analysis, url)\n",
    "            \n",
    "            processing_time = time.time() - start_time\n",
    "            \n",
    "            return {\n",
    "                'url': url,\n",
    "                'success': True,\n",
    "                'result': analysis,\n",
    "                'processing_time': processing_time\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            processing_time = time.time() - start_time\n",
    "            self.logger.error(f\"Failed to process {url}: {e}\")\n",
    "            return {\n",
    "                'url': url,\n",
    "                'success': False,\n",
    "                'error': str(e),\n",
    "                'processing_time': processing_time\n",
    "            }\n",
    "    \n",
    "    def process_videos_parallel(self, video_urls):\n",
    "        \"\"\"Process videos in parallel for maximum performance\"\"\"\n",
    "        results = []\n",
    "        \n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=self.optimal_settings['max_workers']) as executor:\n",
    "            future_to_url = {\n",
    "                executor.submit(self.process_single_video, url): url \n",
    "                for url in video_urls\n",
    "            }\n",
    "            \n",
    "            for future in concurrent.futures.as_completed(future_to_url):\n",
    "                url = future_to_url[future]\n",
    "                try:\n",
    "                    result = future.result()\n",
    "                    results.append(result)\n",
    "                except Exception as e:\n",
    "                    self.logger.error(f\"Error processing {url}: {e}\")\n",
    "                    results.append({\n",
    "                        'url': url,\n",
    "                        'success': False,\n",
    "                        'error': str(e),\n",
    "                        'processing_time': 0\n",
    "                    })\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def run_accelerated_pipeline(self):\n",
    "        \"\"\"Run the accelerated pipeline\"\"\"\n",
    "        self.logger.info(\"Starting Self-Contained Nasdaq Trader Pipeline\")\n",
    "        \n",
    "        # Optimize system\n",
    "        self.optimize_system()\n",
    "        \n",
    "        # Load video URLs\n",
    "        video_urls = self.load_video_urls()\n",
    "        if not video_urls:\n",
    "            self.logger.error(\"No video URLs found\")\n",
    "            return\n",
    "        \n",
    "        self.logger.info(f\"Found {len(video_urls)} videos to process\")\n",
    "        \n",
    "        # Process videos in parallel\n",
    "        results = self.process_videos_parallel(video_urls)\n",
    "        \n",
    "        self.logger.info(\"Self-contained pipeline complete!\")\n",
    "        return results\n",
    "\n",
    "# Initialize and run the self-contained trader\n",
    "print(\"üöÄ Starting SELF-CONTAINED Video Processing\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Initialize the self-contained trader\n",
    "trader = SelfContainedNasdaqTrader()\n",
    "\n",
    "# Run the pipeline\n",
    "results = trader.run_accelerated_pipeline()\n",
    "\n",
    "# Display results\n",
    "if results:\n",
    "    successful = sum(1 for r in results if r['success'])\n",
    "    total_time = sum(r['processing_time'] for r in results)\n",
    "    \n",
    "    print(f\"\\nüìä Processing Results:\")\n",
    "    print(f\"   Videos processed: {len(results)}\")\n",
    "    print(f\"   Successful: {successful}\")\n",
    "    print(f\"   Failed: {len(results) - successful}\")\n",
    "    print(f\"   Total time: {total_time:.2f}s\")\n",
    "    print(f\"   Average per video: {total_time/len(results):.2f}s\")\n",
    "    \n",
    "    # Show individual results\n",
    "    for result in results:\n",
    "        if result['success']:\n",
    "            print(f\"   ‚úÖ {result['url']} - {result['processing_time']:.2f}s\")\n",
    "        else:\n",
    "            print(f\"   ‚ùå {result['url']} - {result['error']}\")\n",
    "    \n",
    "    print(f\"\\nüìÅ Generated files:\")\n",
    "    print(f\"   - Reports: summary/ folder\")\n",
    "    print(f\"   - Audio cache: video_cache/ folder\")\n",
    "    print(f\"   - Transcripts: transcript_cache/ folder\")\n",
    "else:\n",
    "    print(\"‚ùå No results generated\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Report Analysis\n",
    "\n",
    "**Review and analyze generated trading reports**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report Analysis and Review\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"üìä Trading Report Analysis\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# List all generated reports\n",
    "summary_dir = Path(\"summary\")\n",
    "if summary_dir.exists():\n",
    "    report_files = list(summary_dir.glob(\"*.txt\"))\n",
    "    json_files = list(summary_dir.glob(\"*.json\"))\n",
    "    \n",
    "    print(f\"üìÅ Found {len(report_files)} text reports and {len(json_files)} JSON reports\")\n",
    "    \n",
    "    # Display recent reports\n",
    "    if report_files:\n",
    "        latest_report = max(report_files, key=os.path.getctime)\n",
    "        print(f\"\\nüìÑ Latest Report: {latest_report.name}\")\n",
    "        \n",
    "        # Show first few lines of the report\n",
    "        with open(latest_report, 'r', encoding='utf-8') as f:\n",
    "            lines = f.readlines()[:20]  # First 20 lines\n",
    "            print(\"\\nüìã Report Preview:\")\n",
    "            print(\"-\" * 40)\n",
    "            for line in lines:\n",
    "                print(line.rstrip())\n",
    "            if len(f.readlines()) > 20:\n",
    "                print(\"... (report continues)\")\n",
    "    \n",
    "    # Show JSON metadata if available\n",
    "    if json_files:\n",
    "        latest_json = max(json_files, key=os.path.getctime)\n",
    "        print(f\"\\nüìä JSON Metadata: {latest_json.name}\")\n",
    "        \n",
    "        with open(latest_json, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "            print(f\"   Report ID: {data.get('metadata', {}).get('report_id', 'N/A')}\")\n",
    "            print(f\"   Generated: {data.get('metadata', {}).get('generated_timestamp', 'N/A')}\")\n",
    "            print(f\"   Video ID: {data.get('metadata', {}).get('video_id', 'N/A')}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No reports found in summary/ folder\")\n",
    "\n",
    "print(\"\\n‚úÖ Report analysis complete!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Production Best Practices\n",
    "\n",
    "### ‚úÖ Quality Assurance\n",
    "- **Source Validation**: All information comes from video transcripts only\n",
    "- **Ticker Verification**: All ticker symbols are validated\n",
    "- **Price Accuracy**: Only prices explicitly mentioned in videos\n",
    "- **Anti-Hallucination**: No external data or assumptions\n",
    "\n",
    "### üìã Execution Checklist\n",
    "- [ ] Verify `GEMINI_API_KEY` is set\n",
    "- [ ] Add video URLs to `video_list.txt`\n",
    "- [ ] Run processing pipeline\n",
    "- [ ] Review generated reports\n",
    "- [ ] Validate ticker symbols before trading\n",
    "- [ ] Use proper risk management\n",
    "\n",
    "### ‚ö†Ô∏è Important Disclaimers\n",
    "- This analysis is based solely on video content\n",
    "- All tickers and prices should be verified before trading\n",
    "- Past performance does not guarantee future results\n",
    "- Always use proper risk management\n",
    "\n",
    "---\n",
    "\n",
    "**üöÄ Ready for professional trading analysis!**\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Nasdaq Trader",
   "language": "python",
   "name": "nasdaq_trader"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
